{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2df90bf1-fa69-405f-9ccb-1b61e553562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOllama } from \"@langchain/community/chat_models/ollama\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c68d5acf-e99c-4c61-a61d-f8531ffa87b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e15e02b0-6459-45e8-b048-db2d11267e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I help you today? If you have any questions, feel free to ask.\n"
     ]
    }
   ],
   "source": [
    "const model = new ChatOllama({\n",
    "  baseUrl: \"http://localhost:11434\", // Default value\n",
    "  model: \"qwen:0.5b\", // Default value\n",
    "});\n",
    "\n",
    "const stream = await model\n",
    "  .pipe(new StringOutputParser())\n",
    "  .stream(\"hello\");\n",
    "\n",
    "const chunks = [];\n",
    "for await (const chunk of stream) {\n",
    "  chunks.push(chunk);\n",
    "}\n",
    "\n",
    "console.log(chunks.join(\"\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "606304c9-1269-4915-9d46-30419be768c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "const prompt = ChatPromptTemplate.fromMessages([\n",
    "  [\n",
    "    \"system\",\n",
    "    `You are an expert translator. Format all responses as JSON objects with two keys: \"original\" and \"translated\".`,\n",
    "  ],\n",
    "  [\"human\", `Translate \"{input}\" into {language}.`],\n",
    "]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47c6afbc-e506-4190-8df7-9b3211ad0204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "  lc_kwargs: {\n",
      "    content: \u001b[32m'{\\n    \"original\": \"Where are you?\",\\n    \"translated\": \"Where are you?\"\\n}'\u001b[39m,\n",
      "    tool_calls: [],\n",
      "    invalid_tool_calls: [],\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
      "  content: \u001b[32m'{\\n    \"original\": \"Where are you?\",\\n    \"translated\": \"Where are you?\"\\n}'\u001b[39m,\n",
      "  name: \u001b[90mundefined\u001b[39m,\n",
      "  additional_kwargs: {},\n",
      "  response_metadata: {},\n",
      "  tool_calls: [],\n",
      "  invalid_tool_calls: []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const model = new ChatOllama({\n",
    "  baseUrl: \"http://127.0.0.1:11434\", // Default value\n",
    "  model: \"qwen:0.5b\", // Default value\n",
    "  format: \"json\",\n",
    "});\n",
    "\n",
    "const chain = prompt.pipe(model);\n",
    "\n",
    "const result = await chain.invoke({\n",
    "  input: \"在不在\",\n",
    "  language: \"English\"\n",
    "});\n",
    "\n",
    "console.log(result);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a62da7e-ae7a-4c67-9533-3e827e0f8a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nb_converter": "script",
   "pygments_lexer": "typescript",
   "version": "5.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
